{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9516651,"sourceType":"datasetVersion","datasetId":5793737},{"sourceId":2347441,"sourceType":"datasetVersion","datasetId":1417162}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"DA 626 QUESTION-8 210104108","metadata":{}},{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"46349b8e-fb08-45b9-b678-c534a2b30c9f","_cell_guid":"7b1e0c33-8129-4b40-bb24-19b517884d7f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:08:43.177214Z","iopub.execute_input":"2024-10-02T16:08:43.177532Z","iopub.status.idle":"2024-10-02T16:08:43.184541Z","shell.execute_reply.started":"2024-10-02T16:08:43.177497Z","shell.execute_reply":"2024-10-02T16:08:43.183695Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install transformers datasets torch scikit-learn pandas","metadata":{"_uuid":"644c35f1-2c56-4fa7-bd29-669057260d10","_cell_guid":"d6f652b9-c67b-4dcb-a376-77c24231a660","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:08:43.190388Z","iopub.execute_input":"2024-10-02T16:08:43.191123Z","iopub.status.idle":"2024-10-02T16:08:56.096745Z","shell.execute_reply.started":"2024-10-02T16:08:43.191086Z","shell.execute_reply":"2024-10-02T16:08:56.095632Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"e25f8106-bc3d-47c0-bb79-c6e399f011ac","_cell_guid":"cc7ecf47-7df0-4add-8b81-09b7a238254c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:08:56.098621Z","iopub.execute_input":"2024-10-02T16:08:56.098953Z","iopub.status.idle":"2024-10-02T16:09:15.465127Z","shell.execute_reply.started":"2024-10-02T16:08:56.098918Z","shell.execute_reply":"2024-10-02T16:09:15.464352Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Load Data","metadata":{"_uuid":"c69afdcb-06ce-42f0-b4b7-2bd49704f77f","_cell_guid":"da624da5-d13a-451c-9707-69eee5afb85f","trusted":true}},{"cell_type":"code","source":"\n\n# Load train data\ntrain_data = pd.read_csv('/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt', sep=':::', engine='python', names=[\"ID\", \"Title\", \"Genre\", \"Description\"])\n\n# Load test data (without Genre)\ntest_data = pd.read_csv('/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt', sep=':::', engine='python', names=[\"ID\", \"Title\", \"Description\"])\n\n# Combine Title and Description for training and test data\ntrain_data['Text'] = train_data['Title'] + \" \" + train_data['Description']\ntest_data['Text'] = test_data['Title'] + \" \" + test_data['Description']","metadata":{"_uuid":"1c7b0b62-96c4-4728-99e4-0563e63c07b9","_cell_guid":"73d1ef88-4d41-43e5-828a-52b2972959a7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:09:15.466313Z","iopub.execute_input":"2024-10-02T16:09:15.466888Z","iopub.status.idle":"2024-10-02T16:09:17.127301Z","shell.execute_reply.started":"2024-10-02T16:09:15.466854Z","shell.execute_reply":"2024-10-02T16:09:17.126483Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(train_data)","metadata":{"_uuid":"11cf0219-7120-4c58-aebf-9fc72f5792dc","_cell_guid":"174ac6e6-d48b-4bde-8da5-7675911f24a3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:09:17.129289Z","iopub.execute_input":"2024-10-02T16:09:17.129650Z","iopub.status.idle":"2024-10-02T16:09:17.145150Z","shell.execute_reply.started":"2024-10-02T16:09:17.129578Z","shell.execute_reply":"2024-10-02T16:09:17.144120Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"          ID                                         Title          Genre  \\\n0          1                 Oscar et la dame rose (2009)          drama    \n1          2                                 Cupid (1997)       thriller    \n2          3             Young, Wild and Wonderful (1980)          adult    \n3          4                        The Secret Sin (1915)          drama    \n4          5                       The Unrecovered (2007)          drama    \n...      ...                                           ...            ...   \n54209  54210                              \"Bonino\" (1953)         comedy    \n54210  54211                  Dead Girls Don't Cry (????)         horror    \n54211  54212    Ronald Goedemondt: Ze bestaan echt (2008)    documentary    \n54212  54213                     Make Your Own Bed (1944)         comedy    \n54213  54214   Nature's Fury: Storm of the Century (2006)        history    \n\n                                             Description  \\\n0       Listening in to a conversation between his do...   \n1       A brother and sister with a past incestuous r...   \n2       As the bus empties the students for their fie...   \n3       To help their unemployed father make ends mee...   \n4       The film's title refers not only to the un-re...   \n...                                                  ...   \n54209   This short-lived NBC live sitcom centered on ...   \n54210   The NEXT Generation of EXPLOITATION. The sist...   \n54211   Ze bestaan echt, is a stand-up comedy about g...   \n54212   Walter and Vivian live in the country and hav...   \n54213   On Labor Day Weekend, 1935, the most intense ...   \n\n                                                    Text  \n0       Oscar et la dame rose (2009)   Listening in t...  \n1       Cupid (1997)   A brother and sister with a pa...  \n2       Young, Wild and Wonderful (1980)   As the bus...  \n3       The Secret Sin (1915)   To help their unemplo...  \n4       The Unrecovered (2007)   The film's title ref...  \n...                                                  ...  \n54209   \"Bonino\" (1953)   This short-lived NBC live s...  \n54210   Dead Girls Don't Cry (????)   The NEXT Genera...  \n54211   Ronald Goedemondt: Ze bestaan echt (2008)   Z...  \n54212   Make Your Own Bed (1944)   Walter and Vivian ...  \n54213   Nature's Fury: Storm of the Century (2006)   ...  \n\n[54214 rows x 5 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test_data)","metadata":{"_uuid":"5afe9ecc-fe52-40ac-a898-b5e535c21b37","_cell_guid":"93964aef-d9c5-4069-9b96-3e878f86e848","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:09:17.146548Z","iopub.execute_input":"2024-10-02T16:09:17.146913Z","iopub.status.idle":"2024-10-02T16:09:17.157471Z","shell.execute_reply.started":"2024-10-02T16:09:17.146870Z","shell.execute_reply":"2024-10-02T16:09:17.155999Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"          ID                             Title  \\\n0          1             Edgar's Lunch (1998)    \n1          2         La guerra de papá (1977)    \n2          3      Off the Beaten Track (2010)    \n3          4           Meu Amigo Hindu (2015)    \n4          5                Er nu zhai (1955)    \n...      ...                               ...   \n54195  54196   \"Tales of Light & Dark\" (2013)    \n54196  54197      Der letzte Mohikaner (1965)    \n54197  54198              Oliver Twink (2007)    \n54198  54199                Slipstream (1973)    \n54199  54200        Curitiba Zero Grau (2010)    \n\n                                             Description  \\\n0       L.R. Brane loves his life - his car, his apar...   \n1       Spain, March 1964: Quico is a very naughty ch...   \n2       One year in the life of Albin and his family ...   \n3       His father has died, he hasn't spoken with hi...   \n4       Before he was known internationally as a mart...   \n...                                                  ...   \n54195   Covering multiple genres, Tales of Light & Da...   \n54196   As Alice and Cora Munro attempt to find their...   \n54197   A movie 169 years in the making. Oliver Twist...   \n54198   Popular, but mysterious rock D.J Mike Mallard...   \n54199   Curitiba is a city in movement, with rhythms ...   \n\n                                                    Text  \n0       Edgar's Lunch (1998)   L.R. Brane loves his l...  \n1       La guerra de papá (1977)   Spain, March 1964:...  \n2       Off the Beaten Track (2010)   One year in the...  \n3       Meu Amigo Hindu (2015)   His father has died,...  \n4       Er nu zhai (1955)   Before he was known inter...  \n...                                                  ...  \n54195   \"Tales of Light & Dark\" (2013)   Covering mul...  \n54196   Der letzte Mohikaner (1965)   As Alice and Co...  \n54197   Oliver Twink (2007)   A movie 169 years in th...  \n54198   Slipstream (1973)   Popular, but mysterious r...  \n54199   Curitiba Zero Grau (2010)   Curitiba is a cit...  \n\n[54200 rows x 4 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 2: Encode the labels in the training data\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform(train_data['Genre'])","metadata":{"_uuid":"590ec47d-f710-4572-ad5f-ae4a75a7b646","_cell_guid":"5fa3dca9-e7db-48df-a896-6c0f5094c6ce","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:09:17.158698Z","iopub.execute_input":"2024-10-02T16:09:17.158998Z","iopub.status.idle":"2024-10-02T16:09:17.191834Z","shell.execute_reply.started":"2024-10-02T16:09:17.158965Z","shell.execute_reply":"2024-10-02T16:09:17.190956Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Step 3: Tokenize the data using BERT's tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef tokenize_data(data):\n    return tokenizer(data['Text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n\ntrain_encodings = tokenize_data(train_data)\ntest_encodings = tokenize_data(test_data)","metadata":{"_uuid":"df6ea7a5-873e-4f81-94a5-04b87d78dcd7","_cell_guid":"28d934ff-c6d4-42f8-ae15-74fbc5760079","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:09:17.193171Z","iopub.execute_input":"2024-10-02T16:09:17.193617Z","iopub.status.idle":"2024-10-02T16:17:03.274066Z","shell.execute_reply.started":"2024-10-02T16:09:17.193570Z","shell.execute_reply":"2024-10-02T16:17:03.273166Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c1c89d48ea4523951f05cddfb91700"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ba406a370dc42a58615e305b119c854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba4068cdcdb74eca84472b789719d0db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25fdf2ce07414c7eb79409d635bff867"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 4: Create a PyTorch dataset class\nclass MovieDataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        if self.labels is not None:\n            item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\ntrain_dataset = MovieDataset(train_encodings, train_labels)\ntest_dataset = MovieDataset(test_encodings)","metadata":{"_uuid":"ffd3becf-61c5-4df0-b20b-9bb8cc4122c6","_cell_guid":"297e6169-7d7b-4d67-9e8b-94f1a3e5a1c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:17:03.275233Z","iopub.execute_input":"2024-10-02T16:17:03.275551Z","iopub.status.idle":"2024-10-02T16:17:03.282511Z","shell.execute_reply.started":"2024-10-02T16:17:03.275519Z","shell.execute_reply":"2024-10-02T16:17:03.281564Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n\n# Initialize the BERT model for classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    save_strategy=\"no\",\n    logging_dir='./logs',\n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)","metadata":{"_uuid":"c5d49e5f-73cc-4e16-992e-7f2a09e04397","_cell_guid":"95399723-6c54-4eec-9620-b808c290def3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:17:03.283484Z","iopub.execute_input":"2024-10-02T16:17:03.283759Z","iopub.status.idle":"2024-10-02T16:17:07.304037Z","shell.execute_reply.started":"2024-10-02T16:17:03.283730Z","shell.execute_reply":"2024-10-02T16:17:07.303281Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea9f6097063244f6b42e06a45718c171"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-tune the model\ntrainer.train()","metadata":{"_uuid":"476b38bc-532d-4795-8ce7-9d3b6b470f2c","_cell_guid":"1b673191-c9a7-4262-99f4-c555d462e34b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T16:17:07.307130Z","iopub.execute_input":"2024-10-02T16:17:07.307655Z","iopub.status.idle":"2024-10-02T17:29:23.225611Z","shell.execute_reply.started":"2024-10-02T16:17:07.307621Z","shell.execute_reply":"2024-10-02T17:29:23.224476Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241002_163909-egeog7t1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kalrasuhani2-iit-guwahati/huggingface/runs/egeog7t1' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/kalrasuhani2-iit-guwahati/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kalrasuhani2-iit-guwahati/huggingface' target=\"_blank\">https://wandb.ai/kalrasuhani2-iit-guwahati/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kalrasuhani2-iit-guwahati/huggingface/runs/egeog7t1' target=\"_blank\">https://wandb.ai/kalrasuhani2-iit-guwahati/huggingface/runs/egeog7t1</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5085' max='5085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5085/5085 50:10, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.140600</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.802500</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.452300</td>\n      <td>No log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5085, training_loss=0.8490875491702099, metrics={'train_runtime': 4334.4358, 'train_samples_per_second': 37.523, 'train_steps_per_second': 1.173, 'total_flos': 1.070062844306688e+16, 'train_loss': 0.8490875491702099, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"train_preds = trainer.predict(train_dataset)\ntrain_pred_labels = train_preds.predictions.argmax(axis=1)\n\n# Calculate accuracy on the training dataset","metadata":{"_uuid":"52b5dad9-6a77-4dbe-b0f9-06ca11b4b03a","_cell_guid":"8e1b40f3-1b51-48c5-80c4-ef2c4ed1337c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T17:29:23.226916Z","iopub.execute_input":"2024-10-02T17:29:23.227345Z","iopub.status.idle":"2024-10-02T17:33:41.021705Z","shell.execute_reply.started":"2024-10-02T17:29:23.227298Z","shell.execute_reply":"2024-10-02T17:33:41.020983Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"#  from sklearn.metrics import accuracy_score\n#     val_predictions = trainer.predict(val_dataset)\n#     preds = np.argmax(val_predictions.predictions, axis=1)\n\n#     # Calculate accuracy\n#     accuracy = accuracy_score(y_val, preds)\n#     fold_accuracies.append(accuracy)\n#     print(f'Fold Accuracy: {accuracy:.4f}')\n\n# # Calculate and print average accuracy across all folds\n# average_accuracy = np.mean(fold_accuracies)\n# print(f'Average K-Fold Accuracy: {average_accuracy:.4f}')","metadata":{"_uuid":"10a5dad4-8c56-424f-b0a3-e086779899c9","_cell_guid":"b720b847-ba38-4dd4-8d11-12c0b87a0445","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T17:33:41.022885Z","iopub.execute_input":"2024-10-02T17:33:41.023269Z","iopub.status.idle":"2024-10-02T17:33:41.028498Z","shell.execute_reply.started":"2024-10-02T17:33:41.023233Z","shell.execute_reply":"2024-10-02T17:33:41.027626Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrain_accuracy = accuracy_score(train_labels, train_pred_labels)\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"_uuid":"24c27c1e-8409-44e5-a7da-b700252de033","_cell_guid":"fbf9611e-181b-432d-a547-141b785e25f0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T17:33:41.029818Z","iopub.execute_input":"2024-10-02T17:33:41.030271Z","iopub.status.idle":"2024-10-02T17:33:41.046443Z","shell.execute_reply.started":"2024-10-02T17:33:41.030221Z","shell.execute_reply":"2024-10-02T17:33:41.045419Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Training Accuracy: 0.9250\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get predictions\npredictions = trainer.predict(test_dataset)\npredicted_labels = predictions.predictions.argmax(axis=1)\n\n# Convert label indices back to genre names\npredicted_genres = label_encoder.inverse_transform(predicted_labels)","metadata":{"_uuid":"e19469b9-c375-490b-b3c3-fd5c8019e74f","_cell_guid":"17a80723-9dd4-4628-abf8-522a6893ca83","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T17:33:41.047964Z","iopub.execute_input":"2024-10-02T17:33:41.048621Z","iopub.status.idle":"2024-10-02T17:37:57.832708Z","shell.execute_reply.started":"2024-10-02T17:33:41.048572Z","shell.execute_reply":"2024-10-02T17:37:57.831766Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"print(label_encoder.classes_)  # To see all the genres that were encoded","metadata":{"_uuid":"9236f2fd-88f1-4f4c-97f8-b41906ee7023","_cell_guid":"496d6485-869e-4824-a36f-4e3ea3d18353","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T17:37:57.833987Z","iopub.execute_input":"2024-10-02T17:37:57.834381Z","iopub.status.idle":"2024-10-02T17:37:57.841063Z","shell.execute_reply.started":"2024-10-02T17:37:57.834337Z","shell.execute_reply":"2024-10-02T17:37:57.840177Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[' action ' ' adult ' ' adventure ' ' animation ' ' biography ' ' comedy '\n ' crime ' ' documentary ' ' drama ' ' family ' ' fantasy ' ' game-show '\n ' history ' ' horror ' ' music ' ' musical ' ' mystery ' ' news '\n ' reality-tv ' ' romance ' ' sci-fi ' ' short ' ' sport ' ' talk-show '\n ' thriller ' ' war ' ' western ']\n","output_type":"stream"}]},{"cell_type":"code","source":"#to avoid space trailing issue\npredicted_genres_cleaned = [genre.strip() for genre in predicted_genres]\n\n# Create the submission DataFrame with cleaned genres\nsubmission_df = pd.DataFrame({\n    'ID': test_data['ID'],\n    'genre': predicted_genres_cleaned\n})\n\n# Check the unique values in the cleaned predictions\nprint(set(predicted_genres_cleaned))  # Display unique cleaned genres\n\n# Verify the submission DataFrame\nprint(submission_df.head(10))\n\nsubmission_df.to_csv('submission_final.csv', index=False)","metadata":{"_uuid":"702f1ea8-10aa-433a-bc31-0814a4268d06","_cell_guid":"895f55d2-c895-49b3-9a5e-e47a0627ac3f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-02T17:37:57.842534Z","iopub.execute_input":"2024-10-02T17:37:57.842930Z","iopub.status.idle":"2024-10-02T17:37:57.945932Z","shell.execute_reply.started":"2024-10-02T17:37:57.842886Z","shell.execute_reply":"2024-10-02T17:37:57.945016Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'adult', 'romance', 'talk-show', 'family', 'game-show', 'documentary', 'biography', 'thriller', 'musical', 'horror', 'sci-fi', 'western', 'fantasy', 'action', 'short', 'history', 'sport', 'animation', 'mystery', 'war', 'news', 'adventure', 'drama', 'comedy', 'crime', 'music', 'reality-tv'}\n   ID        genre\n0   1     thriller\n1   2       comedy\n2   3  documentary\n3   4        drama\n4   5        drama\n5   6     thriller\n6   7        drama\n7   8       comedy\n8   9  documentary\n9  10        drama\n","output_type":"stream"}]}]}